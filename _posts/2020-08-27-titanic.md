---
title: "Titanic: Machine Learning from Disaster competiton by Kaggle Attempt"
date: 2020-08-23
tags: [titanic, data science, kaggle, supervised learning, random forest, python]
header:
excerpt: "Titanic: Machine Learning from Disaster"
mathjax: "true"
---

In this article, I attempt the Titanic: Machine Learning from Disaster competiton by Kaggle. The problem involves predicting whether passengers on the Titanic would survive or not, based on a number of measurements on the passengers. The full problem description is available on the Kaggle website. This is a supervised learning problem.

Let's begin by importing the libraries we will need to solve the Titanic: Machine Learning from Disaster problem.


```python
import pandas as pd
import seaborn as sns
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import RandomizedSearchCV

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

from sklearn.ensemble import RandomForestClassifier
```

Now, we conduct some exploratory data analysis.


```python
# Import the data
train_df_raw = pd.read_csv("train.csv")

train_df = train_df_raw

# Peek at the dataset
train_df.head
```




    <bound method NDFrame.head of      PassengerId  Survived  Pclass  \
    0              1         0       3   
    1              2         1       1   
    2              3         1       3   
    3              4         1       1   
    4              5         0       3   
    ..           ...       ...     ...   
    886          887         0       2   
    887          888         1       1   
    888          889         0       3   
    889          890         1       1   
    890          891         0       3   
    
                                                      Name     Sex   Age  SibSp  \
    0                              Braund, Mr. Owen Harris    male  22.0      1   
    1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   
    2                               Heikkinen, Miss. Laina  female  26.0      0   
    3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   
    4                             Allen, Mr. William Henry    male  35.0      0   
    ..                                                 ...     ...   ...    ...   
    886                              Montvila, Rev. Juozas    male  27.0      0   
    887                       Graham, Miss. Margaret Edith  female  19.0      0   
    888           Johnston, Miss. Catherine Helen "Carrie"  female   NaN      1   
    889                              Behr, Mr. Karl Howell    male  26.0      0   
    890                                Dooley, Mr. Patrick    male  32.0      0   
    
         Parch            Ticket     Fare Cabin Embarked  
    0        0         A/5 21171   7.2500   NaN        S  
    1        0          PC 17599  71.2833   C85        C  
    2        0  STON/O2. 3101282   7.9250   NaN        S  
    3        0            113803  53.1000  C123        S  
    4        0            373450   8.0500   NaN        S  
    ..     ...               ...      ...   ...      ...  
    886      0            211536  13.0000   NaN        S  
    887      0            112053  30.0000   B42        S  
    888      2        W./C. 6607  23.4500   NaN        S  
    889      0            111369  30.0000  C148        C  
    890      0            370376   7.7500   NaN        Q  
    
    [891 rows x 12 columns]>



You can read the descriptions of the variable names after signing up for the Titanic: Machine Learning from Disaster competiton on Kaggle. Upon reading these descriptions and looking at the head of train_df, I decided to drop Name and Ticket from the feature set as I do not believe that these features would add to any model I may choose to build.


```python
# Drop Name, Ticket, and Cabin
train_df.drop(["Name", "Ticket"], axis=1, inplace=True)

# Determne the types of the variables in train_df
train_df.dtypes
```




    PassengerId      int64
    Survived         int64
    Pclass           int64
    Sex             object
    Age            float64
    SibSp            int64
    Parch            int64
    Fare           float64
    Cabin           object
    Embarked        object
    dtype: object



Now, we determine if any variables contain NA values.


```python
# Determine if there are any NA values 
train_df.isna().sum()
```




    PassengerId      0
    Survived         0
    Pclass           0
    Sex              0
    Age            177
    SibSp            0
    Parch            0
    Fare             0
    Cabin          687
    Embarked         2
    dtype: int64



We see from the above output that Age contains 177 NA values, Cabin contains 687, and Embarked contains 2. Since the majority of values in Cabin are missing, I decided to drop this variable from the set of possible predictors. I have also removed the NA observations in Age and Embarked for the EDA.


```python
# Drop Cabin from train_df
train_df.drop(["Cabin"], axis=1, inplace=True)

# Drop all NA any continue with a complete case analysis
train_df.dropna(axis=0, inplace=True)
```


```python
# Code the response as categorical
train_df["Survived"] = train_df["Survived"].astype("category")
```


```python
# Determine case to control ratio
train_df["Survived"].value_counts()/len(train_df["Survived"])
```




    0    0.595506
    1    0.404494
    Name: Survived, dtype: float64



We see from the above that the data consits of approximately 60% control observations and approximately 40% case observations.

Now, we ananlyse the numeric variables in greater detail, starting with Age.


```python
# Age
sns.catplot(x="Survived", y="Age", kind="box", data=train_df, notch=True)
train_df["Age"].hist(by=train_df["Survived"])
```




    array([<matplotlib.axes._subplots.AxesSubplot object at 0x000001B538D91248>,
           <matplotlib.axes._subplots.AxesSubplot object at 0x000001B538DC7A08>],
          dtype=object)




![png](Titanic_files/Titanic_14_1.png)



![png](Titanic_files/Titanic_14_2.png)


We see from the above box plots that the median of the Age variable does not differ between controls and cases at the 95% confidence level. However, there appear to be minor differences in the distributions of Age for the different categories of teh response, as indicated by the histograms above.

Therefore, I would expect Age to be useful in predictng the response. Now, we move on to Fare.


```python
# Fare
sns.catplot(x="Survived", y="Fare", kind="box", data=train_df, notch=True)
train_df["Fare"].hist(by=train_df["Survived"])
```




    array([<matplotlib.axes._subplots.AxesSubplot object at 0x000001B538F1E4C8>,
           <matplotlib.axes._subplots.AxesSubplot object at 0x000001B538F7B0C8>],
          dtype=object)




<img src="{{ site.url }}{{ site.baseurl }}/images/titanic/fare bar.png" alt="fare bar">



<img src="{{ site.url }}{{ site.baseurl }}/images/titanic/fare hist.png" alt="fare hist">


In contrast to Age, the above box plots indicate that the median level of Fare does differ at the 95% confidence level. Furthermore, there does appear to be differences in the above histograms, with more high fare-paying passengers surviving.

Therefore, I would expect Fare to be useful in predictng the response. 

Now, we analyse the integer variables in greater detail, starting with Pclass.


```python
# Pclass
sns.catplot(y="Survived", hue="Pclass", kind="count",
            palette="pastel", edgecolor=".6",
            data=train_df)
```




    <seaborn.axisgrid.FacetGrid at 0x1b538e13548>




<img src="{{ site.url }}{{ site.baseurl }}/images/titanic/pclass.png" alt="pclass">


There do appear to be differences in the class frequencies between the response groups, with the modal class of perished passengers being 3, whilst the modal class of survivng passengers is 1. 

I would expect Fare to be useful in predictng the response. Now, we move on to SibSp.


```python
# SibSp
sns.catplot(y="Survived", hue="SibSp", kind="count",
            palette="pastel", edgecolor=".6",
            data=train_df)
```




    <seaborn.axisgrid.FacetGrid at 0x1b536a8c348>




<img src="{{ site.url }}{{ site.baseurl }}/images/titanic/SibSp.png" alt="SibSp">


There is some difference in the way that frequencies of each category vary for the two categories of the response. However, I am unsure how useful SibSp will be. Now, we move on to Parch.


```python
# Parch
sns.catplot(y="Survived", hue="Parch", kind="count",
            palette="pastel", edgecolor=".6",
            data=train_df)

```




    <seaborn.axisgrid.FacetGrid at 0x1b53908cc88>




<img src="{{ site.url }}{{ site.baseurl }}/images/titanic/parch.png" alt="parch">


Again, there is some difference in the way that frequencies of each category vary for the two categories of the response. 

I am unsure how useful Parch will be.

Now, we analyse the categorical variables in greater detail.


```python
# Sex
sns.catplot(y="Survived", hue="Sex", kind="count",
            palette="pastel", edgecolor=".6",
            data=train_df)
```




    <seaborn.axisgrid.FacetGrid at 0x1b5391640c8>




<img src="{{ site.url }}{{ site.baseurl }}/images/titanic/sex.png" alt="sex">


Here we see visable differences in the frequency distributions for the two categories of the response. Therefore, I think Sex will be useful in predicting the response. Finally, we analyse Embarked.


```python
# Embarked
sns.catplot(y="Survived", hue="Embarked", kind="count",
            palette="pastel", edgecolor=".6",
            data=train_df)
```




    <seaborn.axisgrid.FacetGrid at 0x1b538bef148>




<img src="{{ site.url }}{{ site.baseurl }}/images/titanic/embarked.png" alt="embarked">


Here, we again observe some difference in the frequencies of each class between the two levels of the response. However, it is challenging to say whether Embarked will add predictive value or not. 

We have now completed our exploratory data analysis of the chosen predictors. Before any modelling can be done, we must split our traning set up into a training and validation set. I have chosen a 75-25 training-validation split. I have also created a dummy variable encoding for all categrical variables (for model fitting). We start with a basic imputation for Age (replace NA with mean of non-missing values), and Embarked (replace NA with mode of non-missing values)


```python
train_df = pd.read_csv("train.csv")

# Replace NAs in Age with the mean of Age
train_df["Age"].fillna(np.mean(train_df["Age"].dropna()), inplace=True)

# Replace NAs in Embarked with mode of Embarked
train_df["Embarked"].fillna(train_df["Embarked"].dropna().mode()[0], inplace=True)

features = ["Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked"]
response = "Survived"

# Prepare the data
X = pd.get_dummies(train_df[features])
y = train_df[response]

# Split the training set up into traning and validate (75-25)
X_train,X_validate,y_train,y_validate=train_test_split(X,y,test_size=0.25,random_state=0)
```

Now, we fit and test out baseline model (the model we compare any more flexible modeling techniques to). I have chosen Linear Discriminant Analysis (LDA) as the baseline model.


```python
# Start with an LDA model as the baselne model
# Instantiate
lda_model = LinearDiscriminantAnalysis()

# Fit
lda_model.fit(X_train, y_train)

# Predict
lda_predictions = lda_model.predict(X_validate)
```

Next, I obtain the confusion matrix for the validation set and the validation set accuracy.


```python
# Confusion matrix
conf_mat_lda = confusion_matrix(y_validate, lda_predictions)
conf_mat_lda
```




    array([[115,  24],
           [ 25,  59]], dtype=int64)




```python
# Validation set accuracy rate
lda_accuracy_validate = lda_model.score(X_validate, y_validate)
lda_accuracy_validate
```




    0.7802690582959642



We see that the LDA achieves a 78.0269% accuracy rate on the validation set.

Now, I fit a more flexible model to see if I can improve this accuracy rate. I have chosen a Random Forest of Classification Trees as the model of increased flexiblity.


```python
# Fit a Random Forest Classifier with the default arguments
rf_model = RandomForestClassifier(n_estimators=1000, max_features = "auto", random_state=0)
rf_model.fit(X_train, y_train)

# Predict
rf_predictions = rf_model.predict(X_validate)

# Confusion matrix
conf_mat_rf = confusion_matrix(y_validate, rf_predictions)
conf_mat_rf
```




    array([[124,  15],
           [ 22,  62]], dtype=int64)




```python
# Validation set accuracy
rf_accuracy_validate = rf_model.score(X_validate, y_validate)
rf_accuracy_validate
```




    0.8340807174887892



We see that a Random Forest of Classification Trees of 1000 trees, fitted with the defualt arguments, achieved an accuracy rate of 83.4081% on the validation set. Now, we examine the feature importance of the features used in constructing the random forest,


```python
# Feature Importance
pd.DataFrame({"Feature":X_train.keys(),"Feature_Importance":rf_model.feature_importances_})
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Feature</th>
      <th>Feature_Importance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Pclass</td>
      <td>0.080173</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Age</td>
      <td>0.260542</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SibSp</td>
      <td>0.053214</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Parch</td>
      <td>0.037212</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fare</td>
      <td>0.240536</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Sex_female</td>
      <td>0.151079</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Sex_male</td>
      <td>0.139853</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Embarked_C</td>
      <td>0.013774</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Embarked_Q</td>
      <td>0.009002</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Embarked_S</td>
      <td>0.014615</td>
    </tr>
  </tbody>
</table>
</div>



We see that Age, Fare and Sex were particularly useful in obtaining predictions of Survived.

Now, we see if we cannot improve the accuracy of the Random Forest of Classification Trees by tuning the hyperparamters, min_samples_split and max_features, with 5-fold cross-validation.


```python
# Tune the Random Forest Classifier
# Create the random grid of hyperparameter values
min_samples_split = [2, 5, 10]

max_features = np.arange(3, 11)

random_grid = {"min_samples_split":min_samples_split, "max_features":max_features}

# Use the random grid to search for best hyperparameters
rf = RandomForestClassifier(n_estimators=1000)

# Use 5-fole cross-validation in selecting the best hyperparameter values
rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter=24, cv = 5, random_state=0)

rf_random.fit(X_train, y_train)

# See best hyperparameter values
rf_random.best_params_
```




    {'min_samples_split': 10, 'max_features': 4}



Now, we select the Random Forest of Classification Trees with the optimal values of the hyperparameters.


```python
# Select the Random Forest Classifier with optimal hyperparameters
rf_model = rf_random.best_estimator_

# Predict
rf_predictions = rf_model.predict(X_validate)

# Confusion matrix
conf_mat_rf = confusion_matrix(y_validate, rf_predictions)
conf_mat_rf
```




    array([[127,  12],
           [ 22,  62]], dtype=int64)




```python
# Validation set accuracy
rf_accuracy_validate = rf_model.score(X_validate, y_validate)
rf_accuracy_validate
```




    0.8475336322869955




```python
# Feature Importance
pd.DataFrame({"Feature":X_train.keys(),"Feature_Importance":rf_model.feature_importances_})
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Feature</th>
      <th>Feature_Importance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Pclass</td>
      <td>0.100185</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Age</td>
      <td>0.186636</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SibSp</td>
      <td>0.051253</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Parch</td>
      <td>0.030693</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fare</td>
      <td>0.190735</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Sex_female</td>
      <td>0.206846</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Sex_male</td>
      <td>0.195253</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Embarked_C</td>
      <td>0.013405</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Embarked_Q</td>
      <td>0.008520</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Embarked_S</td>
      <td>0.016475</td>
    </tr>
  </tbody>
</table>
</div>



We see that the validation set accuracy has now increased to 84.7534%. The feature importance now identifies Sex as the most important predictor. 

I select the Random Forest of Classification Trees as my chosen model for prediction on the test set. Now, I retrain the model on the full training set.


```python
# Refit the Random Forest Classifier with optimal hyperparameters on the full training set
rf_model = RandomForestClassifier(n_estimators=1000, max_features = 4, min_samples_split=10, random_state=0)
rf_model.fit(X, y)
```




    RandomForestClassifier(max_features=4, min_samples_split=10, n_estimators=1000,
                           random_state=0)



Now we apply the same preprocessing to the test set as we did with the training set and obtain the predictions on the test set.


```python
# Import the data
test_df = pd.read_csv("test.csv")

# Peek at the test set
test_df.head
```




    <bound method NDFrame.head of      PassengerId  Pclass                                          Name  \
    0            892       3                              Kelly, Mr. James   
    1            893       3              Wilkes, Mrs. James (Ellen Needs)   
    2            894       2                     Myles, Mr. Thomas Francis   
    3            895       3                              Wirz, Mr. Albert   
    4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   
    ..           ...     ...                                           ...   
    413         1305       3                            Spector, Mr. Woolf   
    414         1306       1                  Oliva y Ocana, Dona. Fermina   
    415         1307       3                  Saether, Mr. Simon Sivertsen   
    416         1308       3                           Ware, Mr. Frederick   
    417         1309       3                      Peter, Master. Michael J   
    
            Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  
    0      male  34.5      0      0              330911    7.8292   NaN        Q  
    1    female  47.0      1      0              363272    7.0000   NaN        S  
    2      male  62.0      0      0              240276    9.6875   NaN        Q  
    3      male  27.0      0      0              315154    8.6625   NaN        S  
    4    female  22.0      1      1             3101298   12.2875   NaN        S  
    ..      ...   ...    ...    ...                 ...       ...   ...      ...  
    413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  
    414  female  39.0      0      0            PC 17758  108.9000  C105        C  
    415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  
    416    male   NaN      0      0              359309    8.0500   NaN        S  
    417    male   NaN      1      1                2668   22.3583   NaN        C  
    
    [418 rows x 11 columns]>




```python
# Drop Name, Ticket, and Cabin
test_df.drop(["Name", "Ticket", "Cabin"], axis=1, inplace=True)

# Determine if there are any NA values 
test_df.isna().sum()
```




    PassengerId     0
    Pclass          0
    Sex             0
    Age            86
    SibSp           0
    Parch           0
    Fare            1
    Embarked        0
    dtype: int64



We see that the test set contains some NA values. We do mean imputation again with the respective training means.


```python
# Replace NAs in Age with the training mean of non-NA Age
test_df["Age"].fillna(np.mean(train_df["Age"].dropna()), inplace=True)

# Replace NAs in Fare with the training mean of non-NA Fare
test_df["Fare"].fillna(np.mean(train_df["Fare"].dropna()), inplace=True)

# Prepare the data
X = pd.get_dummies(test_df[features])
```

Now, we obtain the predictions for the test set.


```python
rf_predictions = rf_model.predict(X)
```


```python
len(rf_predictions)
```




    418




```python
# Create the csv for Kaggle
kaggle_predictions = pd.DataFrame({"PassengerId":test_df["PassengerId"], "Survived":rf_predictions})
kaggle_predictions.head
```




    <bound method NDFrame.head of      PassengerId  Survived
    0            892         0
    1            893         0
    2            894         0
    3            895         0
    4            896         1
    ..           ...       ...
    413         1305         0
    414         1306         1
    415         1307         0
    416         1308         0
    417         1309         0
    
    [418 rows x 2 columns]>



The final Random Forest of Classification Trees model obtained an accuracy rate of 0.7751 on the test set according to Kaggle. 

To improve the accuracy of my predictions, I could have attempted more advanced imputation techniques for Age and Embarked before traning the random forest. I would then apply the same imputaton model to the test set to impute the missing values in Fare and Age. I could also have used a more complex model to estimate a more flexible decision boundary than the one estimated by the random forest. A feedforward neural network for classification is a viable option for a more complex model. 
